(.venv) (base) tanzawaharukanoMacBook-Pro:generate_dataset harukatanzawa$ python lasso_average.py
実験設定:
  データサイズ: n=100, p=200
  スパース率: rho=0.1
  実験回数: 50
  ノイズ分散: Σ=0.1

50回の実験を開始します...
  実験 10/50 完了...
  実験 20/50 完了...
  実験 30/50 完了...
  実験 40/50 完了...
  実験 50/50 完了...
全実験が完了しました。(経過時間: 462.10秒)

======================================================================
【平均結果: ノイズなしの場合】
  最適λ = 0.2560
  平均訓練誤差 = 102.5692
  平均予測誤差 = 19.5365
  誤差比 (予測/訓練) = 0.1905

【平均結果: ノイズありの場合】
  最適λ = 0.2947
  平均訓練誤差 = 105.3939
  平均予測誤差 = 19.3224
  誤差比 (予測/訓練) = 0.1833
======================================================================

グラフを保存しました: results/averaged_error_comparison_20251026_221954.png
平均結果データを保存しました: results/averaged_errors_20251026_221954.csv


⭐️linear_lasso関数内で、ノイズetaを標準化後のスケールに変換する処理を追加：
n# 元のスケールのノイズを標準化後のスケールに変換
eta_scaled = eta / X_sd[:, np.newaxis]


(.venv) (base) tanzawaharukanoMacBook-Pro:generate_dataset harukatanzawa$ python lasso_average.py
実験設定:
  データサイズ: n=100, p=200
  スパース率: rho=0.1
  実験回数: 50
  ノイズ分散: Σ=0.1

50回の実験を開始します...
  実験 10/50 完了...
  実験 20/50 完了...
  実験 30/50 完了...
  実験 40/50 完了...
  実験 50/50 完了...
全実験が完了しました。(経過時間: 450.22秒)

======================================================================
【平均結果: ノイズなしの場合】
  最適λ = 0.2947
  平均訓練誤差 = 103.4078
  平均予測誤差 = 19.0160
  誤差比 (予測/訓練) = 0.1839

【平均結果: ノイズありの場合】
  最適λ = 0.3907
  平均訓練誤差 = 105.3930
  平均予測誤差 = 19.1366
  誤差比 (予測/訓練) = 0.1816
======================================================================

グラフを保存しました: results/averaged_error_comparison_20251026_225935.png
平均結果データを保存しました: results/averaged_errors_20251026_225935.csv

修正前後の比較
修正前
ノイズなし: 予測誤差 = 19.5365
ノイズあり: 予測誤差 = 19.3224  ← 逆転（おかしい）
```
### 修正後
```
ノイズなし: 予測誤差 = 19.0160
ノイズあり: 予測誤差 = 19.1366  ← 正しく悪化している！
```

## 改善点
**予測誤差の大小関係が正常化**
- ノイズありの方が予測誤差が大きくなった（19.0160 → 19.1366）
- これはプライバシー保護のコストとして妥当
**最適λが変化**
- ノイズあり: 0.2947 → 0.3907（より強い正則化が必要に）
- これも理論的に妥当（ノイズに対抗するため）

## ただし、まだ気になる点
**予測誤差の差が小さすぎる**
```
差分: 19.1366 - 19.0160 = 0.1206（約0.6%の悪化）
ノイズ分散Σ=0.1でp=200次元にノイズを加えているのに、予測誤差の悪化がわずか0.6%というのは小さすぎる可能性があります。

⭐️ノイズを大きくしてみる noise分散 = 1.0

(.venv) (base) tanzawaharukanoMacBook-Pro:generate_dataset harukatanzawa$ python lasso_average.py
実験設定:
  データサイズ: n=100, p=200
  スパース率: rho=0.1
  実験回数: 50
  ノイズ分散: Σ=1.0

50回の実験を開始します...
  実験 10/50 完了...
  実験 20/50 完了...
  実験 30/50 完了...
  実験 40/50 完了...
  実験 50/50 完了...
全実験が完了しました。(経過時間: 691.24秒)

======================================================================
【平均結果: ノイズなしの場合】
  最適λ = 0.2947
  平均訓練誤差 = 106.8799
  平均予測誤差 = 19.1165
  誤差比 (予測/訓練) = 0.1789

【平均結果: ノイズありの場合】
  最適λ = 0.5964
  平均訓練誤差 = 109.4899
  平均予測誤差 = 19.2702
  誤差比 (予測/訓練) = 0.1760
======================================================================

グラフを保存しました: results/averaged_error_comparison_20251026_231636.png
平均結果データを保存しました: results/averaged_errors_20251026_231636.csv

予測誤差の悪化がまだ小さい
Σ=0.1→1.0と10倍にノイズを増やしたのに、予測誤差の悪化は：
Σ=0.1: 差0.12 (0.6%)
Σ=1.0: 差0.15 (0.8%)
あまり変わっていないのが疑問。
考えられる理由：
・正則化の効果
λが0.2947→0.5964と大きくなることで、ノイズの影響を相殺している
LASSOのスパース性が強まり、ノイズの影響を受けにくくなっている
・高次元効果
p=200と次元が高いため、個々のノイズの影響が平均化されている
n=100と小さいため、データ自体の変動の方が支配的
・スパース構造
真の係数の90%がゼロなので、ノイズの影響を受ける係数が限定的

プライバシーノイズの影響が予想より小さいのは、
正則化とスパース性のおかげで、差分プライバシーを保ちながら性能劣化を最小限に抑えられているということ

⭐️ノイズをさらに大きくしてみる　noise分散 = 10

(.venv) (base) tanzawaharukanoMacBook-Pro:generate_dataset harukatanzawa$ python lasso_average.py
実験設定:
  データサイズ: n=100, p=200
  スパース率: rho=0.1
  実験回数: 50
  ノイズ分散: Σ=10

50回の実験を開始します...
  実験 10/50 完了...
  実験 20/50 完了...
  実験 30/50 完了...
  実験 40/50 完了...
  実験 50/50 完了...
全実験が完了しました。(経過時間: 916.71秒)

======================================================================
【平均結果: ノイズなしの場合】
  最適λ = 0.2947
  平均訓練誤差 = 106.3794
  平均予測誤差 = 18.5811
  誤差比 (予測/訓練) = 0.1747

【平均結果: ノイズありの場合】
  最適λ = 1.3895
  平均訓練誤差 = 110.1695
  平均予測誤差 = 18.9459
  誤差比 (予測/訓練) = 0.1720
======================================================================

グラフを保存しました: results/averaged_error_comparison_20251026_233559.png
平均結果データを保存しました: results/averaged_errors_20251026_233559.csv

Σ=10という大きなプライバシーノイズを加えても、
適切なλ（1.39）を選択することで、予測誤差の悪化を約2%（18.58→18.95）に抑えられることが実験的に示された

理由
1. 適応的な正則化
λを0.29→1.39と大幅に増やすことで、ノイズの悪影響を相殺
予測誤差の悪化は2%に抑制
2. スパース性の保護効果
真の係数の90%がゼロ
強い正則化により、重要な非ゼロ係数のみを残し、ノイズの影響を最小化
3. 高次元での平均化効果
p=200次元にノイズが分散
個々のノイズの影響が平均化される

結論
プライバシー保護（Σ=10の大きなノイズ）と有用性（予測誤差2%増のみ）の優れたトレードオフを達成している。
これは：
LASSO正則化が差分プライバシーと相性が良いことを示唆
適切なλ選択が重要（1.39 vs 0.29）
スパース回帰問題では、プライバシーコストが小さい可能性を示唆


next action
・予測誤差の理論的な予想値を考える
・λの選択方法について
・平均プライバシー感度を考慮して実験する